{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Matlantis Corp. as contributors to Matlantis contrib project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Condition screening\n",
    "The second screening was conducted to confirm the effect of descriptor type, preprocess, datasize and num_feature.  \n",
    "The results are summarized in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"random_state\": 12345,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_estimators\": 10000,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    #booster=\"gbtree\",\n",
    "    \"objective\": \"reg:absoluteerror\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"n_estimators\": 5000,\n",
    "    \"early_stopping_rounds\": 20,\n",
    "    \"seed\": 12345,\n",
    "    \"max_depth\": 8,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## conditions\n",
    "data_source_name_list = [\"pbev8\", \"r2scan\"] \n",
    "data_source_list = [\"dataset/qm9_vapor_pbev8_H.csv\", \"dataset/qm9_vapor_r2scan_H.csv\"]\n",
    "preprocess_list = [\"MMN+PCA_white\", \"STN+PCA_white\"]  #None, Normarize\n",
    "scaler_name_list = [\"minmax\", \"standard\"]\n",
    "model_name_list =[\"lgb\", \"xgb\"]  # rf, svm\n",
    "num_feature_list = [8, 16, 32, 64, 128, -1] # 5, 10, 25, 50, 100, 250, 8, 16, 32, 64, 128, \n",
    "data_size_list = [100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000, 500000, 2000000] # 100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000, 500000, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data_source, data_source_name in zip(data_source_list, data_source_name_list):    \n",
    "    for preprocess in preprocess_list:\n",
    "        df_h = pd.read_csv(data_source)\n",
    "        ex_cols = [x for x in df_h.columns if x.startswith(\"desc\")]\n",
    "        rest_col = [x for x in df_h.columns if x not in ex_cols]\n",
    "        t_col = \"value\"\n",
    "        group_col = \"molecule_idx\"\n",
    "        X = df_h[ex_cols]\n",
    "\n",
    "        if preprocess is not None:\n",
    "            if preprocess.startswith(\"MMN\"):\n",
    "                scaler = MinMaxScaler()\n",
    "            elif preprocess.startswith(\"STN\"):\n",
    "                scaler = StandardScaler()\n",
    "            \n",
    "            X_norm = X.copy()\n",
    "            X_norm.iloc[:,:] = scaler.fit_transform(X)\n",
    "            \n",
    "            if \"PCA\" in preprocess:\n",
    "                white_flag = True if preprocess.endswith(\"white\") else False\n",
    "                pca = PCA(whiten=white_flag)\n",
    "                X_norm.iloc[:,:] = pca.fit_transform(X_norm)\n",
    "            df_norm = pd.concat([X_norm, df_h[rest_col]], axis=1)\n",
    "        else:\n",
    "            scaler_name = \"non\"\n",
    "            df_norm = df_h\n",
    "            X_norm = X\n",
    "\n",
    "        for data_size in data_size_list:\n",
    "            mol_list = random.sample(list(df_norm[\"molecule_idx\"].unique()), 600)\n",
    "    \n",
    "            df_early = (\n",
    "                df_norm[df_norm[\"molecule_idx\"].isin(mol_list)]\n",
    "                .reset_index()\n",
    "                .drop(columns=\"index\")\n",
    "            )\n",
    "            df_cv = (\n",
    "                df_norm[~df_norm[\"molecule_idx\"].isin(mol_list)]\n",
    "                .reset_index()\n",
    "                .drop(columns=\"index\")\n",
    "            )\n",
    "            data_size = data_size if len(df_cv.index) > data_size else len(df_cv.index)\n",
    "            input_id_list = random.sample(range(len(df_cv.index)), data_size)\n",
    "            df_cv = df_cv.loc[input_id_list, :].reset_index().drop(columns=\"index\")\n",
    "            \n",
    "            #del df_norm\n",
    "            \n",
    "            for num_feat in num_feature_list:\n",
    "                if num_feat != -1:\n",
    "                    if preprocess is None:\n",
    "                        continue\n",
    "                    selected = [True] * num_feat + [False] * (X_norm.shape[1] - num_feat)\n",
    "                else:\n",
    "                    selected = [True] * X_norm.shape[1]\n",
    "    \n",
    "                X = df_cv.copy()[ex_cols]\n",
    "                X = X[X.columns[selected]]\n",
    "                y = df_cv.copy()[t_col]\n",
    "                group = df_cv[group_col]\n",
    "    \n",
    "                X_ea = df_early.copy()[ex_cols]\n",
    "                X_ea = X_ea[X_ea.columns[selected]]\n",
    "                y_ea = df_early.copy()[t_col]\n",
    "                \n",
    "                for model_name in model_name_list:                \n",
    "                    kf = GroupKFold(n_splits=5)\n",
    "                    res_dict = {}\n",
    "    \n",
    "                    for fold, (t_i, v_i) in enumerate(kf.split(X, y, group)):\n",
    "                        X_train, X_valid = X.loc[t_i, :], X.loc[v_i, :]\n",
    "                        y_train, y_valid = y[t_i], y[v_i]\n",
    "    \n",
    "                        if model_name == \"rf\":\n",
    "                            model = RandomForestRegressor(n_jobs=-1, max_depth=10)\n",
    "                        elif model_name == \"lgb\":\n",
    "                            model = lgb.LGBMRegressor(**lgb_params)\n",
    "                        elif model_name == \"xgb\":\n",
    "                            model = xgb.XGBRegressor(**xgb_params)\n",
    "                        \n",
    "                        if isinstance(model, type(lgb.LGBMRegressor())):\n",
    "                            model.fit(\n",
    "                                X_train,\n",
    "                                y_train,\n",
    "                                eval_set=[(X_ea, y_ea)],\n",
    "                                callbacks=[\n",
    "                                    lgb.early_stopping(stopping_rounds=20, verbose=True),\n",
    "                                    lgb.log_evaluation(100),\n",
    "                                ],\n",
    "                            )\n",
    "                        elif isinstance(model, type(xgb.XGBRegressor())):\n",
    "                            model.fit(\n",
    "                                X_train,\n",
    "                                y_train,\n",
    "                                eval_set=[(X_ea, y_ea)],\n",
    "                            )\n",
    "                        else:\n",
    "                            model.fit(X_train, y_train)\n",
    "    \n",
    "                        res_dict.update({fold: [model, X_train, X_valid, y_train, y_valid]})\n",
    "                    \n",
    "                    print(f\"{data_source_name}_{preprocess}_{model_name}_{num_feat} completed\")\n",
    "    \n",
    "                    # evaluate\n",
    "                    train_res_list = []\n",
    "                    val_res_list = []\n",
    "    \n",
    "                    for i in range(5):\n",
    "                        model, X_train, X_valid, y_train, y_valid = res_dict[i]\n",
    "                        train_res_list.append(mean_absolute_error(model.predict(X_train), y_train))\n",
    "                        val_res_list.append(mean_absolute_error(model.predict(X_valid), y_valid))\n",
    "    \n",
    "                    with open(\"res_data_size_feature.txt\", \"a\") as f:\n",
    "                        cnt = f.write(f\"{data_source_name}_{preprocess}_{model_name}_d{data_size}_f{num_feat} Train:{np.mean(train_res_list):.3f} +- {np.std(train_res_list):.3f}, Val:{np.mean(val_res_list):.3f} +- {np.std(val_res_list):.3f}\\n\")\n",
    "            del df_cv, df_early\n",
    "        del X_norm, X, X_ea, y, y_ea, df_norm\n",
    "        del res_dict\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1: Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
